{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install Libraries"
      ],
      "metadata": {
        "id": "irF2Q4L_VBFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community pypdf faiss-cpu openai sentence-transformers"
      ],
      "metadata": {
        "id": "MIUgA986M7wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Drive to access folder"
      ],
      "metadata": {
        "id": "8Y4gWm24Rr1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcVPE6SxRTfX",
        "outputId": "5affdfa5-ae58-497f-ca11-adc094451264"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Libraries"
      ],
      "metadata": {
        "id": "T8uhobJ10k2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEgDUQXdnCgH",
        "outputId": "326a7759-9f3f-4039-c746-5ddee53d9b84"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Secret Credentials via \".env\""
      ],
      "metadata": {
        "id": "XvRFQfpH0phH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load variables from .env file\n",
        "load_dotenv(\"/content/drive/MyDrive/rag_folder/credentials.env\")\n",
        "\n",
        "# Access them\n",
        "AZURE_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
        "AZURE_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "EMBED_MODEL = os.getenv(\"AZURE_EMBED_MODEL\", \"text-embedding-ada-002\")\n",
        "CHAT_MODEL = os.getenv(\"AZURE_CHAT_MODEL\", \"gpt-4o-mini\")\n"
      ],
      "metadata": {
        "id": "5GZ590itnGD7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Azure client in a function"
      ],
      "metadata": {
        "id": "vAMFsX9d1BRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI\n",
        "\n",
        "def get_azure_client():\n",
        "    if not AZURE_KEY or not AZURE_ENDPOINT:\n",
        "        raise ValueError(\"Azure key or endpoint not set in .env\")\n",
        "    return AzureOpenAI(\n",
        "        api_version=\"2025-01-01-preview\",\n",
        "        azure_endpoint=AZURE_ENDPOINT,\n",
        "        api_key=AZURE_KEY\n",
        "    )\n",
        "\n",
        "client = get_azure_client()\n"
      ],
      "metadata": {
        "id": "eDU_VtfQ1CVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Libraries"
      ],
      "metadata": {
        "id": "GWPLpPzAVFWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3iOf3JRmRby_",
        "outputId": "5479e360-719e-477d-e89f-67ec3453e06f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.4.0)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (6.0.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documents Loader function"
      ],
      "metadata": {
        "id": "rX30CguXVJNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pypdf import PdfReader\n",
        "from docx import Document\n",
        "\n",
        "def load_documents_from_drive(folder_path):\n",
        "    documents = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        if filename.lower().endswith(\".pdf\"):\n",
        "            reader = PdfReader(file_path)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                extracted = page.extract_text()\n",
        "                if extracted:\n",
        "                    text += extracted + \"\\n\"\n",
        "            documents.append(text)\n",
        "\n",
        "        elif filename.lower().endswith(\".docx\"):\n",
        "            doc = Document(file_path)\n",
        "            text = \"\"\n",
        "            for para in doc.paragraphs:\n",
        "                text += para.text + \"\\n\"\n",
        "            documents.append(text)\n",
        "\n",
        "    return documents"
      ],
      "metadata": {
        "id": "PzZQo8pISSE3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RAG Pipeline"
      ],
      "metadata": {
        "id": "cgTHzBrRYzZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Documents"
      ],
      "metadata": {
        "id": "K1Ayiq4pYTu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"/content/drive/MyDrive/rag_folder\"\n",
        "documents = load_documents_from_drive(folder)\n",
        "print(\"Loaded\", len(documents), \"documents.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTgKgvOFSV5J",
        "outputId": "bfa13b9b-be61-479e-b5d9-074b1823a088"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2 documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chunk the documents"
      ],
      "metadata": {
        "id": "zTXGHs9PYgGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, chunk_size=300, overlap=50):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(words):\n",
        "        end = start + chunk_size\n",
        "        chunks.append(\" \".join(words[start:end]))\n",
        "        start = end - overlap  # overlap for context continuity\n",
        "    return chunks\n",
        "\n",
        "def build_corpus_chunks(doc_list):\n",
        "    chunks = []\n",
        "    for doc in doc_list:\n",
        "        chunks.extend(chunk_text(doc))\n",
        "    return chunks\n",
        "\n",
        "chunks = build_corpus_chunks(documents)\n",
        "print(\"Total chunks:\", len(chunks))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQfulW9aSyGN",
        "outputId": "a2dcde80-f3a3-4478-b48f-5d9df00a25fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embed the chunks"
      ],
      "metadata": {
        "id": "tXmj1AdrY4Kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI\n",
        "import numpy as np\n",
        "\n",
        "# Azure OpenAI config\n",
        "AZURE_ENDPOINT = \"https://assessment2025-resource.cognitiveservices.azure.com/\"\n",
        "AZURE_KEY = \"EeK1erGEZA2b3ec4sDGzx3JvwUUvAv4YU6LbQ6gWJqKcJya33LK1JQQJ99BKACHYHv6XJ3w3AAAAACOGUL8L\"\n",
        "EMBED_MODEL = \"text-embedding-ada-002\"\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_version=\"2025-01-01-preview\",\n",
        "    azure_endpoint=AZURE_ENDPOINT,\n",
        "    api_key=AZURE_KEY\n",
        ")\n",
        "\n",
        "def embed(texts):\n",
        "    response = client.embeddings.create(\n",
        "        model=EMBED_MODEL,\n",
        "        input=texts\n",
        "    )\n",
        "    return [d.embedding for d in response.data]\n",
        "\n",
        "embeddings = embed(chunks)\n",
        "print(\"Embeddings generated:\", len(embeddings))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDFtFKH7S3py",
        "outputId": "bc88e854-c3a6-49d0-d9f7-ab39389ff681"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings generated: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Libraries"
      ],
      "metadata": {
        "id": "gRGPKrMxY9nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fEQ7xuBaTTPz",
        "outputId": "25ef6291-49ac-4656-ed7c-2fd82af43d76"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build FAISS index"
      ],
      "metadata": {
        "id": "RART8LDQZEdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "dimension = len(embeddings[0])\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(embeddings).astype(\"float32\"))\n",
        "\n",
        "# Map chunk index to actual text\n",
        "chunk_map = {i: chunk for i, chunk in enumerate(chunks)}"
      ],
      "metadata": {
        "id": "eMnu_QiuTTA7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieval function"
      ],
      "metadata": {
        "id": "tDl9Wf7kZJpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query, k=3):\n",
        "    q_emb = embed([query])[0]\n",
        "    scores, idx = index.search(np.array([q_emb]).astype(\"float32\"), k)\n",
        "    results = [chunk_map[int(i)] for i in idx[0]]\n",
        "    return results"
      ],
      "metadata": {
        "id": "vB8ZqlfDTSxp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agent (tool + critic + final answer)"
      ],
      "metadata": {
        "id": "scg3-LCpZS1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHAT_MODEL = \"gpt-4.1-mini\"\n",
        "\n",
        "def call_model(prompt):\n",
        "    res = client.chat.completions.create(\n",
        "        model=CHAT_MODEL,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return res.choices[0].message.content\n",
        "\n",
        "def agent(question):\n",
        "    # Retrieve\n",
        "    retrieved = retrieve(question)\n",
        "    context_text = \"\\n\\n\".join(retrieved)\n",
        "\n",
        "    # Draft answer\n",
        "    draft_prompt = f\"\"\"\n",
        "You are an assistant grounded ONLY in the following retrieved context.\n",
        "\n",
        "Context:\n",
        "{context_text}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Write a grounded answer. If context does not contain the answer, say \"The documents do not contain this information.\"\n",
        "\"\"\"\n",
        "    draft = call_model(draft_prompt)\n",
        "\n",
        "    # Critic\n",
        "    critic_prompt = f\"\"\"\n",
        "Evaluate this answer based on the context.\n",
        "\n",
        "Answer: {draft}\n",
        "\n",
        "Context:\n",
        "{context_text}\n",
        "\n",
        "Is it grounded? Does it hallucinate? Suggest corrections.\n",
        "\"\"\"\n",
        "    critic = call_model(critic_prompt)\n",
        "\n",
        "    # Final answer\n",
        "    final_prompt = f\"\"\"\n",
        "Revise the answer using the critic feedback.\n",
        "\n",
        "Draft answer:\n",
        "{draft}\n",
        "\n",
        "Critic feedback:\n",
        "{critic}\n",
        "\n",
        "Give the final corrected answer.\n",
        "\"\"\"\n",
        "    final_answer = call_model(final_prompt)\n",
        "    return final_answer\n"
      ],
      "metadata": {
        "id": "CLhY-ux_T3eO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple CLI chat loop for Mini Agentic RAG System"
      ],
      "metadata": {
        "id": "6TBgwMlUZZGS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXIuyoF2Ii7u",
        "outputId": "c5b5e585-bf33-4574-e602-dd64c99e8772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mini Agentic RAG System Ready.\n",
            "Type 'exit' to quit.\n",
            "\n",
            "You: What is attention?\n",
            "\n",
            "Agent: Attention is a function that maps a query and a set of key-value pairs to an output, where queries, keys, values, and outputs are vectors—or, when batched, matrices of vectors. The output is computed as a weighted sum of the values, with weights determined by a compatibility function between the queries and keys. Specifically, the Transformer model uses **Scaled Dot-Product Attention**, which calculates the dot products of the query vectors with all key vectors, scales these dot products by dividing by the square root of the key dimension \\( d_k \\), and then applies a softmax function to produce normalized weights. The final output is the weighted sum of the value vectors according to these weights.\n",
            "\n",
            "Formally, the attention output is computed as:\n",
            "\n",
            "\\[\n",
            "Attention(Q, K, V) = softmax\\left(\\frac{QK^{T}}{\\sqrt{d_k}}\\right) V\n",
            "\\]\n",
            "\n",
            "where  \n",
            "- \\( Q \\in \\mathbb{R}^{n \\times d_k} \\) is the matrix of queries,  \n",
            "- \\( K \\in \\mathbb{R}^{m \\times d_k} \\) is the matrix of keys, and  \n",
            "- \\( V \\in \\mathbb{R}^{m \\times d_v} \\) is the matrix of values.\n",
            "\n",
            "This mechanism allows the model to dynamically focus on different parts of the input sequence when producing each element of the output, effectively determining the relevance of each input token to the current processing step.\n",
            "\n",
            "In practice, the Transformer extends this single attention mechanism into **multi-head attention**, which runs several scaled dot-product attention operations in parallel with different learned linear projections of \\( Q, K, \\) and \\( V \\). This enables the model to jointly attend to information from different representation subspaces at different positions, improving its ability to capture diverse contextual relationships. \n",
            "\n",
            "You: Tell me about Recurrent neural network\n",
            "\n",
            "Agent: Recurrent neural networks (RNNs), including long short-term memory (LSTM) and gated recurrent units (GRU), have been firmly established as state-of-the-art approaches in sequence modeling and transduction problems such as language modeling and machine translation. RNNs factor computation along the symbol positions of input and output sequences, generating a sequence of hidden states \\( h_t \\) as a function of the previous hidden state \\( h_{t-1} \\) and the input at position \\( t \\). This sequential nature precludes parallelization within each training example, which becomes a critical bottleneck at longer sequence lengths due to memory constraints limiting efficient batching across examples. Numerous efforts have continued to improve these models’ efficiency and performance, including factorization tricks and conditional computation. These limitations of RNNs—particularly their sequential bottleneck and limited parallelization—motivated the development of alternative architectures like the Transformer, which employ attention mechanisms to enable greater parallelism and improved computational efficiency for modeling long sequences.  \n",
            "[Referenced from the provided context, especially the introduction of the 2017 Transformer paper and related works such as [7], [13]] \n",
            "\n",
            "You: Give me summary of the pdf\n",
            "\n",
            "Agent: The document provides detailed formatting and preparation guidelines for research papers submitted to the journal IJFMR. Key points include:\n",
            "\n",
            "- Use **24 pt, bold, Title Case** font for the paper’s title and **16 pt, bold, Title Case** font for authors’ names. For all other content, use **12 pt Times New Roman** font; **Consolas** is preferred for programming code.\n",
            "\n",
            "- Submit papers as editable files in **.docx or .odt** format, with **no locked or protected regions**.\n",
            "\n",
            "- Set page size to **A4** with margins: **1.60 cm left and right, 1.20 cm top, and 0.60 cm bottom**; use a **single-column layout**, line spacing of **1.15**, and **do not insert page breaks**.\n",
            "\n",
            "- Titles and keywords must be in **Title Case**, avoiding special characters and common lowercase words such as \"a,\" \"an,\" \"the,\" etc.\n",
            "\n",
            "- Align **normal paragraphs justified**, **figures and tables centered**, and **references left-aligned**.\n",
            "\n",
            "- Separate paragraphs with an empty line (no use of before/after paragraph spacing); apply indentation only in numbered or bulleted lists, with approximately a three-space indent after the numbering or bullet.\n",
            "\n",
            "- Avoid **two or more consecutive spaces or blank lines**. Do not use **hard tabs**; instead, apply proper indentation.\n",
            "\n",
            "- Avoid using **Roman numerals** and **italic style** anywhere in the paper.\n",
            "\n",
            "- Define all **abbreviations and acronyms** at their first occurrence in the text.\n",
            "\n",
            "- Use **SI units primarily**, and avoid mixing SI and CGS units to prevent dimensional confusion; CGS or English units may be used secondarily or as identifiers only.\n",
            "\n",
            "- Follow specific punctuation rules: punctuation marks for quotations are placed inside quotation marks; parentheses should surround whole sentences if the parenthetical comment is a complete sentence, otherwise outside.\n",
            "\n",
            "- Writing in the **passive voice** is advised.\n",
            "\n",
            "- Thorough **proofreading for spelling, grammar, and punctuation** is mandatory before submission.\n",
            "\n",
            "- Content must be complete and well-organized before applying formatting.\n",
            "\n",
            "- If an index or table of contents is included, it should be generated automatically using the word processor’s tool to keep page numbers updated.\n",
            "\n",
            "- The **conclusion section** is optional but preferred and should not replicate the abstract.\n",
            "\n",
            "These guidelines ensure a consistent, clear, and professional format for research papers submitted to IJFMR, focusing solely on formatting and preparation without extending beyond those instructions. \n",
            "\n",
            "You: Give me summary of this paper - Attention Is All You Need\n",
            "\n",
            "Agent: The paper *“Attention Is All You Need”* by Vaswani et al. proposes a novel, simple network architecture called the Transformer, which relies solely on attention mechanisms and entirely dispenses with recurrence and convolutions. The model consists of an encoder and a decoder, both built using attention instead of traditional recurrent or convolutional neural networks. \n",
            "\n",
            "Experiments on machine translation tasks demonstrate that the Transformer achieves superior translation quality, is more parallelizable, and requires significantly less training time compared to previous models. Specifically, it attained a BLEU score of 28.4 on the WMT 2014 English-to-German task, surpassing previous best single-model results by over 2 BLEU points—including some ensemble baselines—and a new state-of-the-art single-model BLEU score of 41.8 on the WMT 2014 English-to-French task after 3.5 days of training on eight GPUs. Furthermore, the Transformer generalizes well to other tasks, as shown by its successful application to English constituency parsing with both large and limited amounts of training data.\n",
            "\n",
            "Key technical contributions of the paper include scaled dot-product attention, multi-head attention, and sinusoidal (parameter-free) positional encodings, which allow the model to incorporate sequence order without learned positional embeddings. \n",
            "\n",
            "The architecture also reveals interesting behaviors in its attention heads; for example, some heads capture long-range dependencies and resolve anaphora within sentences, as demonstrated in the paper’s attention visualization analyses.\n",
            "\n",
            "In summary, Vaswani et al.’s Transformer model achieves state-of-the-art results with a simpler architecture and more efficient training by relying entirely on attention mechanisms and innovative positional encoding, marking a significant advance in sequence modeling.\n",
            "\n",
            "*This summary is based on the original work of Vaswani et al. (2017), “Attention Is All You Need.”* \n",
            "\n",
            "You: tell me about bangladesh\n",
            "\n",
            "Agent: The provided documents do not contain this information. The excerpt mainly includes the abstract, author details, and formatting guidelines, but lacks specific details about the requested topic. You may need to consult the full paper or additional resources for more comprehensive information. \n",
            "\n",
            "You: exit\n"
          ]
        }
      ],
      "source": [
        "def chat():\n",
        "    print(\"\\nMini Agentic RAG System Ready.\\nType 'exit' to quit.\\n\")\n",
        "\n",
        "    while True:\n",
        "        q = input(\"You: \")\n",
        "        if q.lower() == \"exit\":\n",
        "            break\n",
        "\n",
        "        ans = agent(q)\n",
        "        print(\"\\nAgent:\", ans, \"\\n\")\n",
        "\n",
        "\n",
        "# Run chat loop if main file\n",
        "if __name__ == \"__main__\":\n",
        "    chat()\n"
      ]
    }
  ]
}
